{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "Import data from a file containing the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# depending on the OS the path to the data file is different\n",
    "if os.name == 'nt':\n",
    "    data = pd.read_csv(r'..\\data\\generated\\preprocessed-data-classification.csv')\n",
    "    food_groups = pd.read_excel(r'..\\data\\food-groups.xls')\n",
    "elif os.name == 'posix':\n",
    "    data = pd.read_csv(r'../data/generated/preprocessed-data-classification.csv')\n",
    "    food_groups = pd.read_excel(r'../data/food-groups.xls')\n",
    "\n",
    "# filter food groups with 'Food Group Code' with length 2\n",
    "food_groups = food_groups[food_groups['Food Group Code'].apply(lambda x: len(str(x)) == 2)]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prepare data\n",
    "1. Determine the target variable.\n",
    "2. Determine the features.\n",
    "3. Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use nutrition columns as features\n",
    "X_COLS = list(data.columns[3:])\n",
    "\n",
    "# use classification column as target\n",
    "y_COL = data.columns[1]\n",
    "\n",
    "print(f\"X_COLS: {X_COLS}\")\n",
    "print(f\"y_COL: {y_COL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data into train and test sets\n",
    "train, test = train_test_split(data, test_size=0.15, random_state=43)\n",
    "\n",
    "# create design matrix X and predictions y\n",
    "X_train = train[X_COLS]\n",
    "y_train = train[y_COL]\n",
    "X_test = test[X_COLS]\n",
    "y_test = test[y_COL]\n",
    "\n",
    "# replace NaN values with 0\n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "y_train = y_train.fillna(0)\n",
    "y_test = y_test.fillna(0)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# $k$-nn\n",
    "We create a $k$-nn model which is used to classify a food into different food groups based on its nutritional information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we determine the best $k$ value based on the accuracy of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best k based on accuracy using cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "def cross_validate(X_train, y_train):\n",
    "    # create list of possible k values from 1 to 100\n",
    "    k_values = list(range(1, 101))\n",
    "\n",
    "    # create list of cross validation scores\n",
    "    cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation for each k \n",
    "    # and take the mean of the scores\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "\n",
    "    # plot the accuracy for each k\n",
    "    plt.plot(k_values, cv_scores)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Cross Validation Mean Accuracy\")\n",
    "\n",
    "    # add xtick for every 5th k\n",
    "    plt.xticks([1] + list(range(5, 101, 5)))\n",
    "\n",
    "    plt.grid()\n",
    "    plt.gcf().set_size_inches(10, 5)\n",
    "    plt.title(\"k-NN Accuracy for Different k Values\")\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig('../report/figs/knn-cross-validation.png', bbox_inches='tight')\n",
    "\n",
    "    # find best k, other than k of 1\n",
    "    cv_scores = [[score, k] for score, k in zip(cv_scores, k_values)]\n",
    "    cv_scores = sorted(cv_scores)\n",
    "    if cv_scores[::-1][0][1] == 1:\n",
    "        best_k = cv_scores[::-1][1][1]\n",
    "        best_k_accuracy = cv_scores[::-1][1][0]\n",
    "    else:\n",
    "        best_k = cv_scores[::-1][0][1]\n",
    "        best_k_accuracy = cv_scores[::-1][0][0]\n",
    "\n",
    "    print(cv_scores[::-1])\n",
    "    print(f\"Best k: {best_k}\")\n",
    "    print(f\"Best k accuracy: {best_k_accuracy}\")\n",
    "\n",
    "    return best_k\n",
    "\n",
    "best_k = cross_validate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_NEIGHBORS = best_k\n",
    "\n",
    "# create knn with best_k neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=KNN_NEIGHBORS)\n",
    "\n",
    "# train the model using the training set\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_y(X_test):\n",
    "    # predict the labels of the test set\n",
    "    return knn.predict(X_test)\n",
    "\n",
    "y_pred = predict_y(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Calculate certain metrics to evaluate the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy_and_predictions(y_test, y_pred):\n",
    "    # y_test constains the true labels of the test set\n",
    "    # y_pred contains the predicted labels of the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "    # compare manually predicted labels with the true labels\n",
    "    print(f\"First few predictions: {y_pred[:10]}\")\n",
    "    print(f\"First few true labels: {y_test[:10].values}\")\n",
    "\n",
    "    return accuracy\n",
    "    \n",
    "print_accuracy_and_predictions(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def print_cm(y_test, y_pred, save_fig=False):\n",
    "    # count the number of correct predictions\n",
    "    print(\"Correct predictions per food group:\")\n",
    "    for value in y_test.unique():\n",
    "        correct = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test.values[i] == y_pred[i] and y_test.values[i] == value:\n",
    "                correct += 1\n",
    "        food_group_name = food_groups[food_groups['Food Group Code'] == value]['Food Group and Sub-Group Name'].values[0].strip()\n",
    "        print(f\"{value}: {correct} ({food_group_name})\")\n",
    "\n",
    "    # create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=y_test.unique())\n",
    "\n",
    "    # create confusion matrix display\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    disp.plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "\n",
    "    # plot the labels on the x and y axis\n",
    "    plt.xticks(range(len(y_test.unique())), y_test.unique())\n",
    "    plt.yticks(range(len(y_test.unique())), y_test.unique())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        disp.figure_.savefig('../report/figs/knn-confusion-matrix.png', bbox_inches='tight')\n",
    "\n",
    "print_cm(y_test, y_pred, save_fig=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "SPLIT_COUNT = 7\n",
    "\n",
    "# splits the data into subsets\n",
    "kfold = KFold(n_splits=SPLIT_COUNT, shuffle=True, random_state=43)\n",
    "\n",
    "accuracy_scores = []\n",
    "for train, test in kfold.split(data):\n",
    "    # create design matrix X and predictions y\n",
    "    X_train = data.iloc[train][X_COLS]\n",
    "    y_train = data.iloc[train][y_COL]\n",
    "    X_test = data.iloc[test][X_COLS]\n",
    "    y_test = data.iloc[test][y_COL]\n",
    "\n",
    "    # reinitialise knn model\n",
    "    knn = KNeighborsClassifier(n_neighbors=KNN_NEIGHBORS)\n",
    "\n",
    "    # train the model using the training subset\n",
    "    knn.fit(X_train, y_train)\n",
    "    \n",
    "    # predict and show\n",
    "    y_pred = predict_y(X_test)\n",
    "    print_accuracy_and_predictions(y_test, y_pred)\n",
    "    print_cm(y_test, y_pred)\n",
    "\n",
    "    # add accuracy to list\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# print average accuracy\n",
    "print(f\"Average accuracy score across {len(accuracy_scores)} CV splits: {sum(accuracy_scores) / len(accuracy_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "N_BOOTSTRAPS = 1000\n",
    "boot_accuracies = []\n",
    "boot_recalls = []\n",
    "boot_precisions = []\n",
    "boot_f1s = []\n",
    "\n",
    "dataid_x = range(np.asarray(X_COLS).shape[0])\n",
    "\n",
    "for i in range(N_BOOTSTRAPS):\n",
    "    \n",
    "    X_boot, y_boot = resample(X_train, y_train, replace=True)\n",
    "    \n",
    "    # predict\n",
    "    y_pred_boot = knn.predict(X_boot)\n",
    "    \n",
    "    # evaluate\n",
    "    boot_accuracies.append(accuracy_score(y_boot, y_pred_boot))\n",
    "    boot_recalls.append(recall_score(y_boot, y_pred_boot, average='macro'))\n",
    "    boot_precisions.append(precision_score(y_boot, y_pred_boot, average='macro'))\n",
    "    boot_f1s.append(f1_score(y_boot, y_pred_boot, average='macro'))\n",
    "\n",
    "# print results\n",
    "print(f\"Bootstrapped accuracies: {boot_accuracies}\")\n",
    "print(f\"Bootstrapped recalls: {boot_recalls}\")\n",
    "print(f\"Bootstrapped precisions: {boot_precisions}\")\n",
    "print(f\"Bootstrapped f1s: {boot_f1s}\")\n",
    "# print averages\n",
    "print(f\"Mean accuracy: {np.mean(boot_accuracies)}\")\n",
    "print(f\"Mean recall: {np.mean(boot_recalls)}\")\n",
    "print(f\"Mean precision: {np.mean(boot_precisions)}\")\n",
    "print(f\"Mean f1: {np.mean(boot_f1s)}\")\n",
    "\n",
    "# plot distribution of accuracy\n",
    "sns.kdeplot(boot_accuracies)\n",
    "plt.title(f\"Accuracy across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.show()\n",
    "\n",
    "# plot distribution of recall\n",
    "sns.kdeplot(boot_recalls)\n",
    "plt.title(f\"Recall across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.show()\n",
    "\n",
    "# plot distribution of precision\n",
    "sns.kdeplot(boot_precisions)\n",
    "plt.title(f\"Precision across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "plt.xlabel(\"Precision\")\n",
    "plt.show()\n",
    "\n",
    "# plot distribution of f1\n",
    "sns.kdeplot(boot_f1s)\n",
    "plt.title(f\"F1 across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "plt.xlabel(\"F1\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
