{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data\n",
    "Import data from a file containing the preprocessed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "V1 = 'First'\n",
    "V2 = 'Second'\n",
    "V3 = 'Third'\n",
    "\n",
    "# depending on the OS the path to the data file is different\n",
    "if os.name == 'nt':\n",
    "    first_data = pd.read_csv(r'..\\data\\generated\\preprocessed-data-classification-first.csv')\n",
    "    second_data = pd.read_csv(r'..\\data\\generated\\preprocessed-data-classification-second.csv')\n",
    "    third_data = pd.read_csv(r'..\\data\\generated\\preprocessed-data-classification-third.csv')\n",
    "    food_groups = pd.read_excel(r'..\\data\\food-groups.xls')\n",
    "elif os.name == 'posix':\n",
    "    first_data = pd.read_csv(r'../data/generated/preprocessed-data-classification-first.csv')\n",
    "    second_data = pd.read_csv(r'../data/generated/preprocessed-data-classification-second.csv')\n",
    "    third_data = pd.read_csv(r'../data/generated/preprocessed-data-classification-third.csv')\n",
    "    food_groups = pd.read_excel(r'../data/food-groups.xls')\n",
    "\n",
    "# filter food groups with 'Food Group Code' with length 2\n",
    "food_groups = food_groups[food_groups['Food Group Code'].apply(lambda x: len(str(x)) == 2)]\n",
    "\n",
    "\n",
    "print('First version of food groups:')\n",
    "first_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Prepare data\n",
    "1. Determine the target variable.\n",
    "2. Determine the features.\n",
    "3. Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_and_target(data, v):\n",
    "    # use nutrition columns as features\n",
    "    X_COLS = list(data.columns[3:])\n",
    "\n",
    "    # use classification column as target\n",
    "    y_COL = data.columns[1]\n",
    "\n",
    "    print(f\"{v} version:\")\n",
    "    print(f\"X_COLS: {X_COLS}\")\n",
    "    print(f\"y_COL: {y_COL}\\n\")\n",
    "    return X_COLS, y_COL\n",
    "\n",
    "first_X_COLS, first_y_COL = feat_and_target(first_data, V1)\n",
    "second_X_COLS, second_y_COL = feat_and_target(second_data, V2)\n",
    "third_X_COLS, third_y_COL = feat_and_target(third_data, V3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TEST_SIZE = 0.15\n",
    "\n",
    "def train_test_data(data, X_COLS, y_COL):\n",
    "    # split data into train and test sets\n",
    "    train, test = train_test_split(data, test_size=TEST_SIZE, random_state=43)\n",
    "\n",
    "    # create design matrix X and predictions y\n",
    "    X_train = train[X_COLS]\n",
    "    y_train = train[y_COL]\n",
    "    X_test = test[X_COLS]\n",
    "    y_test = test[y_COL]\n",
    "\n",
    "    # replace NaN values with 0\n",
    "    X_train = X_train.fillna(0)\n",
    "    X_test = X_test.fillna(0)\n",
    "    y_train = y_train.fillna(0)\n",
    "    y_test = y_test.fillna(0)\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "first_X_train, first_y_train, first_X_test, first_y_test = train_test_data(first_data, first_X_COLS, first_y_COL)\n",
    "second_X_train, second_y_train, second_X_test, second_y_test = train_test_data(second_data, second_X_COLS, second_y_COL)\n",
    "third_X_train, third_y_train, third_X_test, third_y_test = train_test_data(third_data, third_X_COLS, third_y_COL)\n",
    "\n",
    "print(first_y_train.head(50))\n",
    "# print(second_X_test)\n",
    "# print(third_X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# $k$-nn\n",
    "We create a $k$-nn model which is used to classify a food into different food groups based on its nutritional information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we determine the best $k$ value based on the accuracy of different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the best k based on accuracy using cross validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def cross_validate(X_train, y_train, v):\n",
    "    # create list of possible k values from 1 to 100\n",
    "    k_values = list(range(1, 101))\n",
    "\n",
    "    # create list of cross validation scores\n",
    "    cv_scores = []\n",
    "\n",
    "    # perform 10-fold cross validation for each k \n",
    "    # and take the mean of the scores\n",
    "    for k in k_values:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "\n",
    "    # plot the accuracy for each k\n",
    "    plt.plot(k_values, cv_scores)\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"Cross Validation Mean Accuracy\")\n",
    "\n",
    "    # add xtick for every 5th k\n",
    "    plt.xticks([1] + list(range(10, 91, 10)) + [100])\n",
    "\n",
    "    plt.grid()\n",
    "    plt.gcf().set_size_inches(4, 5)\n",
    "    plt.title(\"k-NN Accuracy for Different k Values\")\n",
    "\n",
    "    # save the plot\n",
    "    plt.savefig(f'../report/figs/knn-cross-validation-{v.lower()}.png', bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "    # find best k, other than k of 1\n",
    "    cv_scores = [[score, k] for score, k in zip(cv_scores, k_values)]\n",
    "    cv_scores = sorted(cv_scores)\n",
    "    if cv_scores[::-1][0][1] == 1:\n",
    "        best_k = cv_scores[::-1][1][1]\n",
    "        best_k_accuracy = cv_scores[::-1][1][0]\n",
    "    else:\n",
    "        best_k = cv_scores[::-1][0][1]\n",
    "        best_k_accuracy = cv_scores[::-1][0][0]\n",
    "\n",
    "    print(f\"{v} version:\")\n",
    "    print(cv_scores[::-1])\n",
    "    print(f\"Best k: {best_k}\")\n",
    "    print(f\"Best k accuracy: {best_k_accuracy}\\n\")\n",
    "\n",
    "    return best_k\n",
    "\n",
    "first_best_k = cross_validate(first_X_train, first_y_train, V1)\n",
    "second_best_k = cross_validate(second_X_train, second_y_train, V2)\n",
    "third_best_k = cross_validate(third_X_train, third_y_train, V3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# create knn with best_k neighbors\n",
    "first_knn = KNeighborsClassifier(n_neighbors=first_best_k)\n",
    "# train the model using the training set\n",
    "first_knn.fit(first_X_train, first_y_train)\n",
    "# get first y prediction\n",
    "first_y_pred = first_knn.predict(first_X_test)\n",
    "\n",
    "\n",
    "# create knn with best_k neighbors\n",
    "second_knn = KNeighborsClassifier(n_neighbors=second_best_k)\n",
    "# train the model using the training set\n",
    "second_knn.fit(second_X_train, second_y_train)\n",
    "# get first y prediction\n",
    "second_y_pred = second_knn.predict(second_X_test)\n",
    "\n",
    "\n",
    "# create knn with best_k neighbors\n",
    "third_knn = KNeighborsClassifier(n_neighbors=third_best_k)\n",
    "# train the model using the training set\n",
    "third_knn.fit(third_X_train, third_y_train)\n",
    "# get first y prediction\n",
    "third_y_pred = third_knn.predict(third_X_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Calculate certain metrics to evaluate the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy_and_predictions(y_test, y_pred, v):\n",
    "    print(f\"{v} version:\")\n",
    "    # y_test constains the true labels of the test set\n",
    "    # y_pred contains the predicted labels of the test set\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"\\tAccuracy: {accuracy}\")\n",
    "\n",
    "    # compare manually predicted labels with the true labels\n",
    "    print(f\"\\tFirst few predictions: {y_pred[:10]}\")\n",
    "    print(f\"\\tFirst few true labels: {y_test[:10].values}\\n\")\n",
    "\n",
    "    return accuracy\n",
    "    \n",
    "print_accuracy_and_predictions(first_y_test, first_y_pred, V1)\n",
    "print_accuracy_and_predictions(second_y_test, second_y_pred, V2)\n",
    "print_accuracy_and_predictions(third_y_test, third_y_pred, V3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def print_cm(y_test, y_pred, v, save_fig=False):\n",
    "    print(f\"{v} version:\")\n",
    "\n",
    "    # count the number of correct predictions\n",
    "    print(\"Correct predictions per food group:\")\n",
    "    for value in y_test.unique():\n",
    "        correct = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test.values[i] == y_pred[i] and y_test.values[i] == value:\n",
    "                correct += 1\n",
    "        food_group_name = food_groups[food_groups['Food Group Code'] == value]['Food Group and Sub-Group Name'].values[0].strip()\n",
    "        print(f\"{value}: {correct} ({food_group_name})\")\n",
    "\n",
    "    # create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=y_test.unique())\n",
    "\n",
    "    # create confusion matrix display\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "\n",
    "    # plot confusion matrix\n",
    "    disp.plot()\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "\n",
    "    # plot the labels on the x and y axis\n",
    "    plt.xticks(range(len(y_test.unique())), y_test.unique())\n",
    "    plt.yticks(range(len(y_test.unique())), y_test.unique())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if save_fig:\n",
    "        disp.figure_.savefig(f'../report/figs/knn-confusion-matrix-{v.lower()}.png', bbox_inches='tight')\n",
    "\n",
    "print_cm(first_y_test, first_y_pred, V1, save_fig=True)\n",
    "print_cm(second_y_test, second_y_pred, V2, save_fig=True)\n",
    "print_cm(third_y_test, third_y_pred, V3, save_fig=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "SPLIT_COUNT = 7\n",
    "V1 = 'First'\n",
    "V2 = 'Second'\n",
    "V3 = 'Third'\n",
    "def cross_val_print(X_train, y_train, X_test, y_test, y_pred, k_val, data, X_COLS, y_COL, v):\n",
    "    # splits the data into subsets\n",
    "    kfold = KFold(n_splits=SPLIT_COUNT, shuffle=True, random_state=43)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    for train, test in kfold.split(data):\n",
    "        # create design matrix X and predictions y\n",
    "        X_train = data.iloc[train][X_COLS]\n",
    "        y_train = data.iloc[train][y_COL]\n",
    "        X_test = data.iloc[test][X_COLS]\n",
    "        y_test = data.iloc[test][y_COL]\n",
    "\n",
    "        # reinitialise knn model\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "\n",
    "        # train the model using the training subset\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        # predict and show\n",
    "        y_pred = knn.predict(X_test)\n",
    "\n",
    "        print_accuracy_and_predictions(y_test, y_pred, v)\n",
    "        print_cm(y_test, y_pred, v)\n",
    "\n",
    "        # add accuracy to list\n",
    "        accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # print average accuracy\n",
    "    print(f\"{v} average accuracy score across {len(accuracy_scores)} CV splits: {sum(accuracy_scores) / len(accuracy_scores)}\")\n",
    "\n",
    "cross_val_print(first_X_train, first_y_train, first_X_test, first_y_test, first_y_pred, first_best_k, first_data, first_X_COLS, first_y_COL, V1)\n",
    "cross_val_print(second_X_train, second_y_train, second_X_test, second_y_test, second_y_pred, second_best_k, second_data, second_X_COLS, second_y_COL, V2)\n",
    "cross_val_print(third_X_train, third_y_train, third_X_test, third_y_test, third_y_pred, third_best_k, third_data, third_X_COLS, third_y_COL, V3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score\n",
    "import seaborn as sns\n",
    "\n",
    "def boot_val_print(X_train, y_train, X_test, y_test, y_pred, k_val, data, X_COLS, y_COL, v):\n",
    "    N_BOOTSTRAPS = 1000\n",
    "    boot_accuracies = []\n",
    "    boot_recalls = []\n",
    "    boot_precisions = []\n",
    "    boot_f1s = []\n",
    "\n",
    "    for i in range(N_BOOTSTRAPS):\n",
    "        \n",
    "        X_boot, y_boot = resample(X_train, y_train, replace=True)\n",
    "        \n",
    "        # reinitialise knn model\n",
    "        knn = KNeighborsClassifier(n_neighbors=k_val)\n",
    "\n",
    "        # train the model using the training subset\n",
    "        knn.fit(X_boot, y_boot)\n",
    "        \n",
    "        # predict\n",
    "        y_pred_boot = knn.predict(X_train)\n",
    "        \n",
    "        # evaluate\n",
    "        boot_accuracies.append(accuracy_score(y_train, y_pred_boot))\n",
    "        boot_recalls.append(recall_score(y_train, y_pred_boot, average='macro'))\n",
    "        boot_precisions.append(precision_score(y_train, y_pred_boot, average='macro'))\n",
    "        boot_f1s.append(f1_score(y_train, y_pred_boot, average='macro'))\n",
    "\n",
    "    # print results\n",
    "    print(f\"Bootstrapped accuracies: {boot_accuracies}\")\n",
    "    print(f\"Bootstrapped recalls: {boot_recalls}\")\n",
    "    print(f\"Bootstrapped precisions: {boot_precisions}\")\n",
    "    print(f\"Bootstrapped f1s: {boot_f1s}\")\n",
    "    # print averages\n",
    "    print(f\"Mean accuracy: {np.mean(boot_accuracies)}\")\n",
    "    print(f\"Mean recall: {np.mean(boot_recalls)}\")\n",
    "    print(f\"Mean precision: {np.mean(boot_precisions)}\")\n",
    "    print(f\"Mean f1: {np.mean(boot_f1s)}\")\n",
    "\n",
    "    print(f\"[{v}]\")\n",
    "    # plot distribution of accuracy\n",
    "    sns.kdeplot(boot_accuracies)\n",
    "    plt.title(f\"Accuracy across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "    plt.xlabel(\"Accuracy\")\n",
    "    plt.show()\n",
    "\n",
    "    # plot distribution of recall\n",
    "    sns.kdeplot(boot_recalls)\n",
    "    plt.title(f\"Recall across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.show()\n",
    "\n",
    "    # plot distribution of precision\n",
    "    sns.kdeplot(boot_precisions)\n",
    "    plt.title(f\"Precision across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "    plt.xlabel(\"Precision\")\n",
    "    plt.show()\n",
    "\n",
    "    # plot distribution of f1\n",
    "    sns.kdeplot(boot_f1s)\n",
    "    plt.title(f\"F1 across {N_BOOTSTRAPS} bootstrap samples\")\n",
    "    plt.xlabel(\"F1\")\n",
    "    plt.show()\n",
    "    \n",
    "boot_val_print(first_X_train, first_y_train, first_X_test, first_y_test, first_y_pred, first_best_k, first_data, first_X_COLS, first_y_COL, V1)\n",
    "boot_val_print(second_X_train, second_y_train, second_X_test, second_y_test, second_y_pred, second_best_k, second_data, second_X_COLS, second_y_COL, V2)\n",
    "boot_val_print(third_X_train, third_y_train, third_X_test, third_y_test, third_y_pred, third_best_k, third_data, third_X_COLS, third_y_COL, V3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
